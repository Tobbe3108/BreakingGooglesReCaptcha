<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Breaking Google‚Äôs Image-based reCaptcha v2 | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Breaking Google‚Äôs Image-based reCaptcha v2" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Breaking Google‚Äôs Image-based reCaptcha v2." />
<meta property="og:description" content="Breaking Google‚Äôs Image-based reCaptcha v2." />
<link rel="canonical" href="https://tobbe3108.github.io/BreakingGooglesRecaptcha/markdown/2021/05/25/Breaking-Google-s-Image-based-reCaptcha-v2.html" />
<meta property="og:url" content="https://tobbe3108.github.io/BreakingGooglesRecaptcha/markdown/2021/05/25/Breaking-Google-s-Image-based-reCaptcha-v2.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-05-25T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Breaking Google‚Äôs Image-based reCaptcha v2.","url":"https://tobbe3108.github.io/BreakingGooglesRecaptcha/markdown/2021/05/25/Breaking-Google-s-Image-based-reCaptcha-v2.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://tobbe3108.github.io/BreakingGooglesRecaptcha/markdown/2021/05/25/Breaking-Google-s-Image-based-reCaptcha-v2.html"},"headline":"Breaking Google‚Äôs Image-based reCaptcha v2","dateModified":"2021-05-25T00:00:00-05:00","datePublished":"2021-05-25T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/BreakingGooglesRecaptcha/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://tobbe3108.github.io/BreakingGooglesRecaptcha/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/BreakingGooglesRecaptcha/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/BreakingGooglesRecaptcha/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/BreakingGooglesRecaptcha/about/">About Me</a><a class="page-link" href="/BreakingGooglesRecaptcha/search/">Search</a><a class="page-link" href="/BreakingGooglesRecaptcha/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Breaking Google‚Äôs Image-based reCaptcha v2</h1><p class="page-description">Breaking Google‚Äôs Image-based reCaptcha v2.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-05-25T00:00:00-05:00" itemprop="datePublished">
        May 25, 2021
      </time>
       ‚Ä¢ <span class="read-time" title="Estimated read time">
    
    
      17 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/BreakingGooglesRecaptcha/categories/#markdown">markdown</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#collect-data">Collect Data</a></li>
<li class="toc-entry toc-h2"><a href="#prepare-the-data">Prepare the data</a>
<ul>
<li class="toc-entry toc-h3"><a href="#ops√¶tning-af-datablock">Ops√¶tning af datablock</a></li>
<li class="toc-entry toc-h3"><a href="#d√•rlige-billeder">D√•rlige billeder</a></li>
<li class="toc-entry toc-h3"><a href="#resultat">Resultat</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#choose-the-model">Choose the model</a></li>
<li class="toc-entry toc-h2"><a href="#train-your-machine-model">Train your machine model</a></li>
<li class="toc-entry toc-h2"><a href="#evaluation">Evaluation</a></li>
<li class="toc-entry toc-h2"><a href="#tuning--optimisation">Tuning / Optimisation</a></li>
<li class="toc-entry toc-h2"><a href="#prediction">Prediction</a></li>
<li class="toc-entry toc-h2"><a href="#neurale-netv√¶rk">Neurale netv√¶rk</a>
<ul>
<li class="toc-entry toc-h3"><a href="#stochastic-gradient-descent">Stochastic Gradient Descent</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#optimering">Optimering</a>
<ul>
<li class="toc-entry toc-h3"><a href="#smoothing-label-smoothing">Smoothing (Label Smoothing)</a>
<ul>
<li class="toc-entry toc-h4"><a href="#sidebar">Sidebar</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#fastai">Fastai</a>
<ul>
<li class="toc-entry toc-h3"><a href="#dataloaders">DataLoaders</a></li>
</ul>
</li>
</ul><p>I dette projekt har vi valgt at vi vil fors√∏ge at bryde Google‚Äôs reCAPTCHA v2 med et neuralt netv√¶rk.
reCAPTCHA tester den menneskelige evne til at genkende objekter p√• billeder, derfor er det en oplagt opgave at fors√∏ge at l√∏se med et neuralt netv√¶rk.
Mange virksomheder er for l√¶ngst skiftet v√¶k fra reCAPTCHA v2 til andre bedre alternativer, men man st√∏der stadig ofte p√• denne reCAPTCHA.</p>

<h2 id="collect-data">
<a class="anchor" href="#collect-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Collect Data</h2>
<p>Da vi skulle finde et datas√¶t til at tr√¶ne vores model, pr√∏vede vi at google ‚Äúrecaptcha datas√¶t‚Äù, for at se om der allerede var nogen der havde lavet et. 3. link f√∏rte til en github repository kaldet <a href="https://github.com/brian-the-dev/recaptcha-dataset"><em>recaptcha-dataset</em></a>.
Efter et n√¶rmere kig p√• billederne i datas√¶ttet, viste det sig at v√¶re et rigtig godt udgangspunkt for vores projekt.
Datas√¶ttet indeholder mere end 10.000 billeder, fordelt p√• 11 kategorier s√•som ‚ÄúBicycle‚Äù, ‚ÄúCrosswalk‚Äù og ‚ÄúTraffic Light‚Äù, som er det man ofte skal identificere i googles recaptcha.
Desuden er billederne allerede skaleret ned og besk√•ret til et 1:1 format, p√• samme m√•de som i recaptchaen. Datas√¶ttet er ogs√• frigivet under en MIT licens, s√• vi uden bekymringer kan g√∏re brug af det.</p>

<p>En potentiel udfordring ved datas√¶ttet er dog, at flere af billederne passer ind i flere kategorier.
Fx er der mange af billederne af ‚ÄúTraffic Lights‚Äù som ogs√• indeholder en ‚ÄúCrosswalk‚Äù.
Datas√¶ttet er dog lavet s√•dan, at hvert billede kun er i en kategori, og tager ikke h√∏jde for om det passer ind flere steder.</p>

<p>Efter at have downloadet datas√¶ttet valgte vi midlertidigt at trimme st√∏rstedelen af billederne v√¶k, s√• der kun var en lille m√¶ngde billeder i hver kategori.
Det gjorde vi for at g√∏re det hurtigere at tr√¶ne modellen under de indledende kode-iterationer.
F√∏rst da vi var overbeviste om at vi havde styr p√• koden, tr√¶nede vi modellen op imod det fulde datas√¶t.</p>

<h2 id="prepare-the-data">
<a class="anchor" href="#prepare-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prepare the data</h2>
<h3 id="ops√¶tning-af-datablock">
<a class="anchor" href="#ops%C3%A6tning-af-datablock" aria-hidden="true"><span class="octicon octicon-link"></span></a>Ops√¶tning af datablock</h3>
<p>Forberedelsen af data‚Äôen sker i vores datablock.
Vores block er en ImageBlock som er MultiCategoryBlock. Det vil alts√• sige at vi vil have modellen har mulighed for at kunne genkende mere end et label p√• billederne.</p>

<p>get_items bliver hentet gennem fastai‚Äôs get_image_files metode.
get_y bliver sat gennem egen metode get_y som s√¶tter parent_label til billedet.
splitter bliver sat efter default parametre hvor der er en valid_pct p√• 0.2 og seed er 42.
item_tfms s√¶ttes til 128 og min_scale til 0.35. Dette g√∏r at billederne har en minimumsst√∏rrelse p√• 128 pixels med en scale p√• minimum 0.35</p>

<p>N√•r modellens datablock bliver instansieret s√¶ttes der ikke en batch_tfms.
I dette tilf√¶lde betyder det at fastai automatisk f√•r lov til at normalisere data‚Äôen udfra en enkelt batch af data‚Äôen.</p>

<h3 id="d√•rlige-billeder">
<a class="anchor" href="#d%C3%A5rlige-billeder" aria-hidden="true"><span class="octicon octicon-link"></span></a>D√•rlige billeder</h3>
<p>I det datas√¶t som der er blevet fundet er der ikke blevet fjernet d√•rlige billeder.
Dette skyldes bl.a. at en reCaptcha er sat op til at kunne have d√•rlige billeder, hvor det som der bliver spurgt efter ikke n√∏dvendigvis er i fokus eller god kvalitet.</p>
<h3 id="resultat">
<a class="anchor" href="#resultat" aria-hidden="true"><span class="octicon octicon-link"></span></a>Resultat</h3>
<p>Som det kan ses i ops√¶tning af datablock‚Äôen, s√• er de fleste v√¶rdier ‚Äúdefault‚Äù v√¶rdier, som fastai anbefaler man benytter i f√∏rste ops√¶tning.
Dette har vi ikke ydeligere modificeret p√• eftersom at vores baseline model har resulteret i en accuracy p√• op til 94%.</p>

<h2 id="choose-the-model">
<a class="anchor" href="#choose-the-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Choose the model</h2>
<p>Et konventionelt neural networks network design har hver enkelte node forbundet til alle noder finding in i alle node i n√¶ste lag.
Dette g√∏r at backprobergationen selv skal finde m√∏nstre og segmentere datagen.
Med et Convolutional Neural Networks tvinger man netv√¶rket til at kun at kigge p√• mindre segmenter i stedet for selv at g√∏re det.
Med Convolutional Neural Networks findes der mange strategier man kan bruge til en neural Network design s√• som LeNet-5, AlexNet og VGG-16.
I vores projekt har vi brugt den indbygget cnn learner for multi category block.
Vi bruger Multi Category Block da det var et krav men ogs√• lader os benytte vores ressourcer bedre da vi kan tjekke hvad Recapture sp√∏rg efter samtidig med billederne bliver labeled.</p>

<p><img src="https://tobbe3108.github.io/BreakingGooglesRecaptcha/images/Screenshot_1.png" alt=""></p>

<p>Mens vi unders√∏gte hvordan vi optimerer vores model valgte vi at lave et mindre datas√¶t end havde vi oprindeligt fandt. 
Dette gjorde at vi kunne iterere hurtigere da det tog kortere tid at tr√¶ne n√•r vi laver √¶ndringer i vores l√¶rings parameter.
Ulemper med denne tilgang er tendenser i vores tr√¶ning s√¶t bliver forst√¶rket fx de fleste modeller vi har tr√¶net har ikke haft multi category labels p√• billederne men derimod kun et label.
Dette gjorde hvis der var en bro og en bil p√• samme billede, ville den kun v√¶lge den ene frem for begge. Mere om dette under Prediction afsnittet.
Vi er endt med en model det svare med Multi Category Block og bruger fastai‚Äôs indbyggede cnn lerner, og for hurtig iteration har vi et mindre datas√¶t.</p>

<p><img src="https://tobbe3108.github.io/BreakingGooglesRecaptcha/images/Screenshot_2.png" alt=""></p>

<h2 id="train-your-machine-model">
<a class="anchor" href="#train-your-machine-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train your machine model</h2>
<p>Med dataene og fremgangsm√•den redegjort for, er vores projekt i tr√¶ningsfasen.
Her f√∏lger vi tr√¶ningen igennem vores udvalgte data, og validerer gennem fasens epochs hvilke antagelser som modellen laver, og hvilke der ender ud med at v√¶re korrekte.</p>

<p>I datasamlingen fortalte vi om vores opdeling af vores datagrundlag og en test sample, som er trimmet ned for at tillade at den indledende tr√¶ning forl√∏ber hurtigt.
Dette g√∏r at vi kan opbygge vores optimale indstillinger for tr√¶ningen og klarg√∏re til det komplette datagrundlag.</p>

<p>Vi kan fors√∏ge os med at tilf√∏je flere k√∏rsler i form af Epochs for at finde ud af hvilken kvantitet af tr√¶ning der giver os umiddelbart den bedste n√∏jagtighed.
I vores trimmede dataset k√∏rer Epochs hurtigt, og giver os et indblik i hvilke resultater vi kan forvente.</p>

<p>I tr√¶ningen eksperimenterer vi ogs√• med forskellige Resnets for at g√∏re tr√¶ningen hurtigere, hvilket baner vejen for en hurtig opstart i de f√∏rste Epochs, som s√• tilf√∏jer de mest komplekse layers tilbage i de senere Epochs for at opbygge et grundlag for modellen og validere den til sidst.
Vi valgte at g√• med Resnet50, da vi havde st√∏rst accuracy med testen undervejs og havde mest erfaring med denne m√¶ngde.</p>

<p>Det giver ogs√• mening at effektuere tr√¶ningen ved hj√¶lp af CNN learner‚Äôens Learning Rate Find metode.
Dette giver et indblik i hvordan CNN bedst kan l√¶rer ud fra vores data p√• den mest ressourceeffektive m√•de.</p>

<h2 id="evaluation">
<a class="anchor" href="#evaluation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Evaluation</h2>
<p><a href="https://tobbe3108.github.io/BreakingGooglesRecaptcha/2021/05/25/Captcha-Baseline-Model.html">Baseline model notebook</a></p>

<p>For ikke at skulle tr√¶ne modellen p√• alle 10.000 billeder hver gang da det taget lang tid har vi lavet et datas√¶t der tager 20 billeder fra hver kategori.
Dette datas√¶t har vi efterf√∏lgende brugt til vores aktive udvikling.
N√•r vi har haft en ny model iteration vi gerne ville teste helt, har vi skiftet tilbage til det oprindelige datas√¶t med 10.000 billeder.
Vi har oplevet at dette lille datas√¶t har v√¶ret tilstr√¶kkeligt til at give en indikation af hvor godt modellen er.</p>

<p>I vores DataBlock har vi benyttet en RandomSplitter der udv√¶lger 0.2 procent af billederne som vores valideringss√¶t.
Billederne bliver ogs√• alle k√∏rt igennem en RandomResizedCrop der g√∏r at vi f√•r mere variation i vores data.</p>

<p>Vi har benyttet den indbyggede leaning rate finder (Lr_find()) til at finde den optimale learning rate for vores learner.
Lr_find() metoden k√∏re et par iterationer med en meget lille learning rate.
For hvert mini-batch bliver der skruet en lille smule op for learning raten indtil den til sidst er meget h√∏j.
Iterationernes loss bliver sammenlignet med den valgte learning rate og den bedste bliver valgt.</p>

<p>Da vi tr√¶nede denne model f√∏rste gang med ovenst√•ende udgangspunkt, blev vi meget overraskede over at vores model opn√•ede en accuracy p√• 94%.
Da vi testede modellen med et billede den aldrig have set f√∏r blev vi lige s√• overraskede.
Modellen var 99.6% sikker p√• at der er bro i det billede, men den var kun 0.07% sikker p√• at der var en bil ogs√• selv om det er meget tydeligt at se at der b√•de er biler og en bro.
Dette betyder at vi har lavet en model der er rigtig god til at finde en enkelt ting i et billede men alts√• ikke flere ting som vores model skal kunne.</p>

<p>Vi har alligevel valgt at beholde denne model som vores baseline model p√• trods af dette da den giver et godt udgangspunkt vi kan teste vores fremtidige iterationer op imod.</p>

<h2 id="tuning--optimisation">
<a class="anchor" href="#tuning--optimisation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tuning / Optimisation</h2>
<p><a href="https://tobbe3108.github.io/BreakingGooglesRecaptcha/2021/05/25/Captcha-MixUp.html">MixUp notebook</a><br>
<a href="https://tobbe3108.github.io/BreakingGooglesRecaptcha/2021/05/25/Captcha-LabelSmoothing.html">Label Smoothing v1 notebook</a><br>
<a href="https://tobbe3108.github.io/BreakingGooglesRecaptcha/2021/05/25/Captcha-Label-Smoothing-v2.html">Label Smoothing v2 notebook</a><br>
<a href="https://tobbe3108.github.io/BreakingGooglesRecaptcha/2021/05/25/Captcha-Label-Correction.html">Label Correction notebook</a></p>

<p>Med vores nyoprettet baseline model, justerer vi vores forskellige parameter for at opn√• det bedste resultat.
For at sikre imod at vores model blev for sikker og ‚Äúoverfitted‚Äù, brugte vi Label Smoothing undervejs i tr√¶ningen for at g√∏re modellen mere modtagelig over for et mere nuanceret g√¶t i sidste ende, s√•dan at modellen kan v√¶re bedre til at g√¶tte p√• andre mulige resultater i de billeder, som vi skal genkende.
Dette er rigtig nyttigt, til billeder som indeholder fx biler og broer, hvor at begge klassifikationer er korrekte, og g√∏r at vi kan validere om modellen tror at en bestemt kategori findes p√• billedet.
N√•r reCAPTCHA s√• sp√∏rger efter alle bjergene p√• en r√¶kke billeder, s√• er det ikke et problem at der er en bil p√• nogle af billederne.
Vores model kan stadig v√¶lge at kigge efter den specifikke kategori, beregner hvorvidt der er en sandsynlighed for at et billede indeholder et bjerg og kan p√• den m√•de stadig svare rigtig.
Dette kr√¶ver dog bare at vi specificerer et threshold for hvor lav sandsynlighed der skulle accepteres.</p>

<p>Til sidst i vores fors√∏g p√• at optimere vores model, tilf√∏jede vi en Mixup Callback metode til vores learner for at give bedre n√∏jagtighed p√• vores billedgenkendelse.
Med Mixup kan vi blande vores billeder sammen for at billederne skal genkendes ind over hinanden i et fors√∏g p√• at g√∏re learneren √•ben over for tvetydighed i vores data.
N√•r vores learner st√∏der p√• et billede der er opbygget af 20 % biler og 80 % lyskryds, vil vores forventning v√¶re at den bliver bedre til at opdage flere kategorier i hvert billede, hvilket i sidste ende vil forbedre vores metode.
Det kan desuden ogs√• diskuteres over at vores model ikke skal v√¶re perfekt, da et menneske liges√• godt kan tage fejl af et objekt i et billede, hvilket Mixup ogs√• kunne tilf√∏je til vores model.</p>

<h2 id="prediction">
<a class="anchor" href="#prediction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prediction</h2>
<p>Efter som vi arbejder med en Multi Category block har vi haft sv√¶rt ved at bruge de mange af de redskaber vi er blevet undervist i s√• som confusion matrixen.
Da vores billeder prim√¶rt kun har haft et labelt p√• har vi under det meste af udviklen haft stor bios i visse tilf√¶lde.
Fx har der ofte v√¶ret biler p√• billeder med bruger dette har f√•et AI‚Äôen til at v√¶re sikker p√• bruger frem for biler n√•r der de har optr√•dt i samme billede.
Tobias lavede en csv fil p√• vores lille datas√¶t for at migrere dette problem.
Vi har pr√∏vet at k√∏re vores model mod en ‚Äúrigtig‚Äù recapture billeder fra https://www.google.com/recaptcha/api2/demo.
I stedet for at l√¶se html siden med Python downloade vi billedet og manuelt splitte det i de 9 billeder, hvor vi efterf√∏lgende putte det ind i vores AI.
Vi endte med det nedenst√•ende resultat, den fangede n√¶sten alle cyklerne den eneste den mistede var 2,3.
Dette kunne skyldes at vi ikke bruger hele vore dataset da vi tr√¶nede denne model men i stedet vores mindre tr√¶ningss√¶t.</p>

<p><img src="https://tobbe3108.github.io/BreakingGooglesRecaptcha/images/Screenshot_3.png" alt=""><br>
Image: 1, 1.jpg Prediction: [‚ÄòBicycle‚Äô]; Bicycle Probability: 0.9659770131111145<br>
Image: 1, 2.jpg Prediction: [‚ÄòBicycle‚Äô]; Bicycle Probability: 0.9705190062522888<br>
Image: 1, 3.jpg Prediction: [‚ÄòBridge‚Äô]; Bicycle Probability: 4.990302880554836e-18</p>

<p><img src="https://tobbe3108.github.io/BreakingGooglesRecaptcha/images/Screenshot_4.png" alt=""><br>
Image: 2, 1.jpg Prediction: [‚ÄòPalm‚Äô]; Bicycle Probability: 0.044423192739486694<br>
Image: 2, 2.jpg Prediction: []; Bicycle Probability: 0.4902642071247101<br>
Image: 2, 3.jpg Prediction: []; Bicycle Probability: 0.20381507277488708</p>

<p><img src="https://tobbe3108.github.io/BreakingGooglesRecaptcha/images/Screenshot_5.png" alt=""><br>
Image: 3, 1.jpg Prediction: [‚ÄòPalm‚Äô]; Bicycle Probability: 0.007280856370925903<br>
Image: 3, 2.jpg Prediction: [‚ÄòCrosswalk‚Äô]; Bicycle Probability: 0.00545891746878624<br>
Image: 3, 3.jpg Prediction: [‚ÄòChimney‚Äô]; Bicycle Probability: 0.003270353190600872</p>

<p>Vi pr√∏vede igen men en model der var tr√¶net p√• hele vores datas√¶t og det s√• meget mere lovende ud.</p>

<p><img src="https://tobbe3108.github.io/BreakingGooglesRecaptcha/images/Screenshot_3.png" alt=""><br>
Image: 1, 1.jpg Prediction: [‚ÄòBicycle‚Äô]; Bicycle Probability: 0.9953802824020386<br>
Image: 1, 2.jpg Prediction: [‚ÄòBicycle‚Äô]; Bicycle Probability: 0.9892680048942566<br>
Image: 1, 3.jpg Prediction: [‚ÄòBridge‚Äô]; Bicycle Probability: 0.0003413711965549737</p>

<p><img src="https://tobbe3108.github.io/BreakingGooglesRecaptcha/images/Screenshot_4.png" alt=""><br>
Image: 2, 1.jpg Prediction: [‚ÄòPalm‚Äô]; Bicycle Probability: 0.0001781134633347392<br>
Image: 2, 2.jpg Prediction: [‚ÄòCar‚Äô]; Bicycle Probability: 0.003861015196889639<br>
Image: 2, 3.jpg Prediction: [‚ÄòBicycle‚Äô]; Bicycle Probability: 0.8249829411506653</p>

<p><img src="https://tobbe3108.github.io/BreakingGooglesRecaptcha/images/Screenshot_5.png" alt="">
Image: 3, 1.jpg Prediction: [‚ÄòCar‚Äô]; Bicycle Probability: 0.0001316472189500928<br>
Image: 3, 2.jpg Prediction: [‚ÄòCrosswalk‚Äô]; Bicycle Probability: 0.0038241292349994183<br>
Image: 3, 3.jpg Prediction: [‚ÄòOther‚Äô]; Bicycle Probability: 0.0007099288050085306</p>

<h2 id="neurale-netv√¶rk">
<a class="anchor" href="#neurale-netv%C3%A6rk" aria-hidden="true"><span class="octicon octicon-link"></span></a>Neurale netv√¶rk</h2>
<h3 id="stochastic-gradient-descent">
<a class="anchor" href="#stochastic-gradient-descent" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stochastic Gradient Descent</h3>
<p>For at kunne tr√¶ne vores model s√• den kan blive bedre til at lave forudsigelser p√• vores data, skal vi bruge en m√•de at √¶ndre vores weights.
Dette kan g√∏res p√• flere m√•der men en meget brugt m√•de er Gradient Descent eller n√¶rmere Stochastic Gradient Descent.
Gradient Descent og Stochastic Gradient Descent g√∏r det samme og er identiske p√• n√¶r at man i Stochastic Gradient Descent tager lidt data og k√∏re igennem i stedet for alt data som i Gradient Descent.
Dette g√∏r ogs√• at Stochastic Gradient Descent er meget mere egnet til arbejde med BIG DATA da du ikke skal lave lige s√• mange udregnigner for hver epoch.</p>

<p>Man kan forklare hvad Gradient Descent g√•r ud p√• ved at forestille sig at man skal finde den korteste ved ned af et bjerg.
Hvis man bruger traditionel Gradient Descent til at finde den korteste vej, udregner man den optimale rute p√• en gang ved at bruge data om alle de forskellige veje der er p√• bjerget.
Denne l√∏sning giver med garanti den korteste vej ned af bjerget, men det bliver ogs√• sv√¶rere og sv√¶rere at lave udregningen jo mere data man har om bjerget.
Hvis man derimod bruger Stochastic Gradient Descent til at finde vej ned af bjerget, vil man g√• ud og kigge p√• de mulige veje man kan tage p√• nuv√¶rende tidspunkt.
Man g√•r s√• ned ad den vej der f√∏rer en l√¶ngst ned at bjerget.
Hvis vejen er meget stejl g√•r man lige lidt l√¶nger af denne vej inden man igen kigger efter en ny vej der f√∏rer en l√¶ngere og l√¶ngere ned af bjerget.
Det g√∏r man igen og igen til man har n√•et bunden.</p>

<p>Hvis vi pr√∏ver helt simpelt at overf√∏re dette til vores neurale netv√¶rk vil det alts√• sige at vi tager en lille del af vores data og sender det igennem vores neurale netv√¶rk.
Vi udregner gradienten for den data og bruger den til at opdatere modellens weights.
Vi g√∏r s√• det hele igen med en anden lille del af vores data. Denne proces kan illustreres p√• f√∏lgende m√•de:</p>

<p><img src="https://tobbe3108.github.io/BreakingGooglesRecaptcha/images/Screenshot_6.png" alt=""></p>

<ol>
  <li>Init: Da vi skal have et udgangspunkt for vores weights bliver de i dette step initialiseret til tilf√¶ldige v√¶rdiger.</li>
  <li>Predict: I dette step bruger vi de tilf√¶ldige weights til at f√• en prediction ved at k√∏re en lille del af dataen igennem det neurale netv√¶rk.</li>
  <li>Loss: I dette step bruger vi en loss function til at m√•le modellens effektivitet med de nuv√¶rende weights.</li>
  <li>Gradient: I dette step udregner vi vores gradient som fort√¶ller os hvordan √¶ndringen af en weight vil p√•virke vores loss.</li>
  <li>Step: I dette step √¶ndrer vi v√¶rdierne af vores weights p√• baggrund af den udregnede gradient. Hvis der stadig er flere epochs tilbage, g√•r vi tilbage til step 2 og gentager de efterf√∏lgende step.</li>
  <li>Stop: N√•r der ikke er flere epochs g√•r vi ikke tilbage til step 2 men stopper derimod bare.</li>
</ol>

<p>Det vigtige i denne proces er alts√• step 4 hvor vi udregner vores gradient.
Gradient er bare et fancy ord for derivative der kommer fra calculus.
S√• n√•r vi siger at vi udregner vores gradient udregner vi i realiteten derivative for vores loss function.
Teknisk fortalt er derivative en funktion der beregner slope for en funktion ved en given v√¶rdi.
Mere simpelt fortelt fort√¶ller derivative os hvor stejl bjerget er p√• en given vej.</p>

<h2 id="optimering">
<a class="anchor" href="#optimering" aria-hidden="true"><span class="octicon octicon-link"></span></a>Optimering</h2>
<h3 id="smoothing-label-smoothing">
<a class="anchor" href="#smoothing-label-smoothing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Smoothing (Label Smoothing)</h3>

<p>N√•r vores model bliver tr√¶net s√• er vores m√•l i teorien at f√• et resultat der bliver 1.
Dette er resultatet p√• modellens ‚Äúg√¶t‚Äù ogs√• selvom den ikke er 100% sikker.
Dette betyder ogs√• at de resterende kategorier bliver 0.
Denne tilgang giver tendens til overfitting, og en model som ikke giver betydelig respons p√• dens g√¶t.</p>

<p>For at undg√• dette s√• kan man under ops√¶tningen af sin model have en loss function som benytter sig af Label Smoothing.
Label smoothing s√∏rger for at modellen kommer med et mere generaliserende g√¶t, ved at erstatte alle 1‚Äôerne med et tal mindre end 1 og alle 0‚Äôerne med (ùùê / N), hvor ùùê (epsilon) er et parameter oftest 0,1 og N er antallet af klasser.</p>

<p>N√•r vi tr√¶ner modellen vil vi stadig gerne have at alle labels til sammen giver resultatet 1, derfor erstatter vi 1 (det label som der bliver g√¶ttet p√•) med f√∏lgende formel: (1-ùùê+ùùê/N).</p>

<p><strong>This maximum is not achievable for finite  zk  but is approached if  zy‚â´zk  for all  k‚â†y</strong></p>

<p>Hvis man g√•r over i den teoretiske forst√•else af label smoothing, s√• er det en matematisk algoritme (st√•ende ovenfor) som beviser at maximum ikke er opn√•eligt.</p>

<p>Hvis man deler algoritmen op, s√• er y vores target og zy den activation som er tilh√∏rende det target.
For at komme t√¶t p√• 1, s√• skal zy v√¶re st√∏rre end ved alle andre ‚Äúg√¶t‚Äù.
Dybere i algoritmen bliver det forklaret, at hvis modellen l√¶rer at tildele fuld sandsynlighed p√• labellet ved hver tr√¶ning, s√• er den ikke garanteret at kunne generalisere.
Det som det betyder er at hvis zy har en h√∏j/stor v√¶rdi, s√• skal der benyttes st√∏rre weights og activations gennem modellen.
Dette kan resultere i at sm√• √¶ndringen i input (f.eks. √¶ndring i en pixel) kan give en helt anden probability n√•r der bliver g√¶ttet.</p>

<p>Hvis man holder algoritmen op sammen med Bounded Gradient, s√• reducerer det modellens evne til at kunne tilpasse sig.</p>

<h4 id="sidebar">
<a class="anchor" href="#sidebar" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sidebar</h4>
<p>Benyttelse af Label smoothing ses ofte kun ved Single-Label.
Selve matematikken bag Label smoothing er i f√∏rste omgang tilegnet Single-Label, og man vil derfor skulle have en forst√•else for at kunne √¶ndre i selve algoritmens matematik for at kunne benytte Label smoothing ved Multi-Label.</p>

<p>Det har ikke v√¶ret muligt at finde nogle endnu som har kn√¶kket den matematiske kode til at benytte Label smoothing p√• Multi-Label.
Den offentlige debat lyder i hvert fald p√• at det i det nuv√¶rende omfang ikke er muligt at benytte Label smoothing p√• Multi-Label modeller.</p>

<h2 id="fastai">
<a class="anchor" href="#fastai" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fastai</h2>
<h3 id="dataloaders">
<a class="anchor" href="#dataloaders" aria-hidden="true"><span class="octicon octicon-link"></span></a>DataLoaders</h3>
<p>DataLoaders er en meget simpel klasse, som bare wrapper/indeholder en r√¶kke DataLoader objekter.
Det er dog den som st√•r for at levere data til modellen, og det er derfor en meget central del af FastAI.</p>

<p>Der er flere m√•der man kan lave ens DataLoaders objekt p√•.
FastAI indeholder en r√¶kke s√•kaldte ‚Äúfactory methods‚Äù, som returnerer DataLoaders med pr√¶definerede ops√¶tninger.
Det er en smart m√•de at spare tid p√•, hvis det man laver er s√• ‚Äúalmindeligt‚Äù at der allerede er en ops√¶tning, som passer. 
Alternativt kan man lave en custom DataLoaders. For at g√∏re det, bruges data block API‚Äôen.</p>

<p>N√•r man laver en custom DataLoaders skal f√∏lgende angives, for at modellen kan tr√¶nes:</p>
<ul>
  <li>Independent variable</li>
  <li>Dependent variable</li>
  <li>Hvordan skal data hentes</li>
  <li>Validation set</li>
  <li>Labels</li>
</ul>

<p>Derudover kan man angive item transforms, som er noget kode der bliver k√∏rt p√• hver entry i datas√¶ttet.
P√• samme m√•de som med DataLoaders har FastAI en r√¶kke indbyggede transforms, til de mest g√¶ngse operationer, men det er ogs√• muligt at kode sin egen.
De indbyggede transforms inkluderer fx cropping og resizing af billeder.</p>

<p>Som et alternativ til item transforms, kan man bruge batch transforms.
Med en batch transform k√∏rer man i stedet noget kode p√• hele batchen i stedet for hvert individuelt billede, hvilket kan v√¶re hurtigere at udf√∏re. 
transform kan fx bruges i forbindelse med data augmentation af billeder, efter de er blevet croppet og/eller resizet til alle at v√¶re den samme st√∏rrelse.</p>

  </div><a class="u-url" href="/BreakingGooglesRecaptcha/markdown/2021/05/25/Breaking-Google-s-Image-based-reCaptcha-v2.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/BreakingGooglesRecaptcha/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/BreakingGooglesRecaptcha/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/BreakingGooglesRecaptcha/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/BreakingGooglesRecaptcha/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/BreakingGooglesRecaptcha/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
