{
  
    
        "post0": {
            "title": "Breaking Google’s Image-based reCaptcha v2",
            "content": "Breaking Google’s Image-based reCaptcha v2 . I dette projekt har vi valgt at vi vil forsøge at bryde Google’s reCAPTCHA v2 med et neuralt netværk. reCAPTCHA tester den menneskelige evne til at genkende objekter på billeder, derfor er det en oplagt opgave at forsøge at løse med et neuralt netværk. Mange virksomheder er for længst skiftet væk fra reCAPTCHA v2 til andre bedre alternativer, men man støder stadig ofte på denne reCAPTCHA. . Collect Data . Da vi skulle finde et datasæt til at træne vores model, prøvede vi at google “recaptcha datasæt”, for at se om der allerede var nogen der havde lavet et. 3. link førte til en github repository kaldet recaptcha-dataset. Efter et nærmere kig på billederne i datasættet, viste det sig at være et rigtig godt udgangspunkt for vores projekt. Datasættet indeholder mere end 10.000 billeder, fordelt på 11 kategorier såsom “Bicycle”, “Crosswalk” og “Traffic Light”, som er det man ofte skal identificere i googles recaptcha. Desuden er billederne allerede skaleret ned og beskåret til et 1:1 format, på samme måde som i recaptchaen. Datasættet er også frigivet under en MIT licens, så vi uden bekymringer kan gøre brug af det. . En potentiel udfordring ved datasættet er dog, at flere af billederne passer ind i flere kategorier. Fx er der mange af billederne af “Traffic Lights” som også indeholder en “Crosswalk”. Datasættet er dog lavet sådan, at hvert billede kun er i en kategori, og tager ikke højde for om det passer ind flere steder. . Efter at have downloadet datasættet valgte vi midlertidigt at trimme størstedelen af billederne væk, så der kun var en lille mængde billeder i hver kategori. Det gjorde vi for at gøre det hurtigere at træne modellen under de indledende kode-iterationer. Først da vi var overbeviste om at vi havde styr på koden, trænede vi modellen op imod det fulde datasæt. . Prepare the data . Opsætning af datablock . Forberedelsen af data’en sker i vores datablock. Vores block er en ImageBlock som er MultiCategoryBlock. Det vil altså sige at vi vil have modellen har mulighed for at kunne genkende mere end et label på billederne. . get_items bliver hentet gennem fastai’s get_image_files metode. get_y bliver sat gennem egen metode get_y som sætter parent_label til billedet. splitter bliver sat efter default parametre hvor der er en valid_pct på 0.2 og seed er 42. item_tfms sættes til 128 og min_scale til 0.35. Dette gør at billederne har en minimumsstørrelse på 128 pixels med en scale på minimum 0.35 . Når modellens datablock bliver instansieret sættes der ikke en batch_tfms. I dette tilfælde betyder det at fastai automatisk får lov til at normalisere data’en udfra en enkelt batch af data’en. . Dårlige billeder . I det datasæt som der er blevet fundet er der ikke blevet fjernet dårlige billeder. Dette skyldes bl.a. at en reCaptcha er sat op til at kunne have dårlige billeder, hvor det som der bliver spurgt efter ikke nødvendigvis er i fokus eller god kvalitet. . Resultat . Som det kan ses i opsætning af datablock’en, så er de fleste værdier “default” værdier, som fastai anbefaler man benytter i første opsætning. Dette har vi ikke ydeligere modificeret på eftersom at vores baseline model har resulteret i en accuracy på op til 94%. . Choose the model . Et konventionelt neural networks network design har hver enkelte node forbundet til alle noder finding in i alle node i næste lag. Dette gør at backprobergationen selv skal finde mønstre og segmentere datagen. Med et Convolutional Neural Networks tvinger man netværket til at kun at kigge på mindre segmenter i stedet for selv at gøre det. Med Convolutional Neural Networks findes der mange strategier man kan bruge til en neural Network design så som LeNet-5, AlexNet og VGG-16. I vores projekt har vi brugt den indbygget cnn learner for multi category block. Vi bruger Multi Category Block da det var et krav men også lader os benytte vores ressourcer bedre da vi kan tjekke hvad Recapture spørg efter samtidig med billederne bliver labeled. . . Mens vi undersøgte hvordan vi optimerer vores model valgte vi at lave et mindre datasæt end havde vi oprindeligt fandt. Dette gjorde at vi kunne iterere hurtigere da det tog kortere tid at træne når vi laver ændringer i vores lærings parameter. Ulemper med denne tilgang er tendenser i vores træning sæt bliver forstærket fx de fleste modeller vi har trænet har ikke haft multi category labels på billederne men derimod kun et label. Dette gjorde hvis der var en bro og en bil på samme billede, ville den kun vælge den ene frem for begge. Mere om dette under Prediction afsnittet. Vi er endt med en model det svare med Multi Category Block og bruger fastai’s indbyggede cnn lerner, og for hurtig iteration har vi et mindre datasæt. . . Train your machine model . Med dataene og fremgangsmåden redegjort for, er vores projekt i træningsfasen. Her følger vi træningen igennem vores udvalgte data, og validerer gennem fasens epochs hvilke antagelser som modellen laver, og hvilke der ender ud med at være korrekte. . I datasamlingen fortalte vi om vores opdeling af vores datagrundlag og en test sample, som er trimmet ned for at tillade at den indledende træning forløber hurtigt. Dette gør at vi kan opbygge vores optimale indstillinger for træningen og klargøre til det komplette datagrundlag. . Vi kan forsøge os med at tilføje flere kørsler i form af Epochs for at finde ud af hvilken kvantitet af træning der giver os umiddelbart den bedste nøjagtighed. I vores trimmede dataset kører Epochs hurtigt, og giver os et indblik i hvilke resultater vi kan forvente. . I træningen eksperimenterer vi også med forskellige Resnets for at gøre træningen hurtigere, hvilket baner vejen for en hurtig opstart i de første Epochs, som så tilføjer de mest komplekse layers tilbage i de senere Epochs for at opbygge et grundlag for modellen og validere den til sidst. Vi valgte at gå med Resnet50, da vi havde størst accuracy med testen undervejs og havde mest erfaring med denne mængde. . Det giver også mening at effektuere træningen ved hjælp af CNN learner’ens Learning Rate Find metode. Dette giver et indblik i hvordan CNN bedst kan lærer ud fra vores data på den mest ressourceeffektive måde. . Evaluation . Baseline model notebook . For ikke at skulle træne modellen på alle 10.000 billeder hver gang da det taget lang tid har vi lavet et datasæt der tager 20 billeder fra hver kategori. Dette datasæt har vi efterfølgende brugt til vores aktive udvikling. Når vi har haft en ny model iteration vi gerne ville teste helt, har vi skiftet tilbage til det oprindelige datasæt med 10.000 billeder. Vi har oplevet at dette lille datasæt har været tilstrækkeligt til at give en indikation af hvor godt modellen er. . I vores DataBlock har vi benyttet en RandomSplitter der udvælger 0.2 procent af billederne som vores valideringssæt. Billederne bliver også alle kørt igennem en RandomResizedCrop der gør at vi får mere variation i vores data. . Vi har benyttet den indbyggede leaning rate finder (Lr_find()) til at finde den optimale learning rate for vores learner. Lr_find() metoden køre et par iterationer med en meget lille learning rate. For hvert mini-batch bliver der skruet en lille smule op for learning raten indtil den til sidst er meget høj. Iterationernes loss bliver sammenlignet med den valgte learning rate og den bedste bliver valgt. . Da vi trænede denne model første gang med ovenstående udgangspunkt, blev vi meget overraskede over at vores model opnåede en accuracy på 94%. Da vi testede modellen med et billede den aldrig have set før blev vi lige så overraskede. Modellen var 99.6% sikker på at der er bro i det billede, men den var kun 0.07% sikker på at der var en bil også selv om det er meget tydeligt at se at der både er biler og en bro. Dette betyder at vi har lavet en model der er rigtig god til at finde en enkelt ting i et billede men altså ikke flere ting som vores model skal kunne. . Vi har alligevel valgt at beholde denne model som vores baseline model på trods af dette da den giver et godt udgangspunkt vi kan teste vores fremtidige iterationer op imod. . Tuning / Optimisation . MixUp notebook Label Smoothing v1 notebook Label Smoothing v2 notebook Label Correction notebook . Med vores nyoprettet baseline model, justerer vi vores forskellige parameter for at opnå det bedste resultat. For at sikre imod at vores model blev for sikker og “overfitted”, brugte vi Label Smoothing undervejs i træningen for at gøre modellen mere modtagelig over for et mere nuanceret gæt i sidste ende, sådan at modellen kan være bedre til at gætte på andre mulige resultater i de billeder, som vi skal genkende. Dette er rigtig nyttigt, til billeder som indeholder fx biler og broer, hvor at begge klassifikationer er korrekte, og gør at vi kan validere om modellen tror at en bestemt kategori findes på billedet. Når reCAPTCHA så spørger efter alle bjergene på en række billeder, så er det ikke et problem at der er en bil på nogle af billederne. Vores model kan stadig vælge at kigge efter den specifikke kategori, beregner hvorvidt der er en sandsynlighed for at et billede indeholder et bjerg og kan på den måde stadig svare rigtig. Dette kræver dog bare at vi specificerer et threshold for hvor lav sandsynlighed der skulle accepteres. . Til sidst i vores forsøg på at optimere vores model, tilføjede vi en Mixup Callback metode til vores learner for at give bedre nøjagtighed på vores billedgenkendelse. Med Mixup kan vi blande vores billeder sammen for at billederne skal genkendes ind over hinanden i et forsøg på at gøre learneren åben over for tvetydighed i vores data. Når vores learner støder på et billede der er opbygget af 20 % biler og 80 % lyskryds, vil vores forventning være at den bliver bedre til at opdage flere kategorier i hvert billede, hvilket i sidste ende vil forbedre vores metode. Det kan desuden også diskuteres over at vores model ikke skal være perfekt, da et menneske ligeså godt kan tage fejl af et objekt i et billede, hvilket Mixup også kunne tilføje til vores model. . Prediction . Efter som vi arbejder med en Multi Category block har vi haft svært ved at bruge de mange af de redskaber vi er blevet undervist i så som confusion matrixen. Da vores billeder primært kun har haft et labelt på har vi under det meste af udviklen haft stor bios i visse tilfælde. Fx har der ofte været biler på billeder med bruger dette har fået AI’en til at være sikker på bruger frem for biler når der de har optrådt i samme billede. Tobias lavede en csv fil på vores lille datasæt for at migrere dette problem. Vi har prøvet at køre vores model mod en “rigtig” recapture billeder fra https://www.google.com/recaptcha/api2/demo. I stedet for at læse html siden med Python downloade vi billedet og manuelt splitte det i de 9 billeder, hvor vi efterfølgende putte det ind i vores AI. Vi endte med det nedenstående resultat, den fangede næsten alle cyklerne den eneste den mistede var 2,3. Dette kunne skyldes at vi ikke bruger hele vore dataset da vi trænede denne model men i stedet vores mindre træningssæt. . Image: 1, 1.jpg Prediction: [‘Bicycle’]; Bicycle Probability: 0.9659770131111145 Image: 1, 2.jpg Prediction: [‘Bicycle’]; Bicycle Probability: 0.9705190062522888 Image: 1, 3.jpg Prediction: [‘Bridge’]; Bicycle Probability: 4.990302880554836e-18 . Image: 2, 1.jpg Prediction: [‘Palm’]; Bicycle Probability: 0.044423192739486694 Image: 2, 2.jpg Prediction: []; Bicycle Probability: 0.4902642071247101 Image: 2, 3.jpg Prediction: []; Bicycle Probability: 0.20381507277488708 . Image: 3, 1.jpg Prediction: [‘Palm’]; Bicycle Probability: 0.007280856370925903 Image: 3, 2.jpg Prediction: [‘Crosswalk’]; Bicycle Probability: 0.00545891746878624 Image: 3, 3.jpg Prediction: [‘Chimney’]; Bicycle Probability: 0.003270353190600872 . Vi prøvede igen men en model der var trænet på hele vores datasæt og det så meget mere lovende ud. . Image: 1, 1.jpg Prediction: [‘Bicycle’]; Bicycle Probability: 0.9953802824020386 Image: 1, 2.jpg Prediction: [‘Bicycle’]; Bicycle Probability: 0.9892680048942566 Image: 1, 3.jpg Prediction: [‘Bridge’]; Bicycle Probability: 0.0003413711965549737 . Image: 2, 1.jpg Prediction: [‘Palm’]; Bicycle Probability: 0.0001781134633347392 Image: 2, 2.jpg Prediction: [‘Car’]; Bicycle Probability: 0.003861015196889639 Image: 2, 3.jpg Prediction: [‘Bicycle’]; Bicycle Probability: 0.8249829411506653 . Image: 3, 1.jpg Prediction: [‘Car’]; Bicycle Probability: 0.0001316472189500928 Image: 3, 2.jpg Prediction: [‘Crosswalk’]; Bicycle Probability: 0.0038241292349994183 Image: 3, 3.jpg Prediction: [‘Other’]; Bicycle Probability: 0.0007099288050085306 . Neurale netværk . Stochastic Gradient Descent . For at kunne træne vores model så den kan blive bedre til at lave forudsigelser på vores data, skal vi bruge en måde at ændre vores weights. Dette kan gøres på flere måder men en meget brugt måde er Gradient Descent eller nærmere Stochastic Gradient Descent. Gradient Descent og Stochastic Gradient Descent gør det samme og er identiske på nær at man i Stochastic Gradient Descent tager lidt data og køre igennem i stedet for alt data som i Gradient Descent. Dette gør også at Stochastic Gradient Descent er meget mere egnet til arbejde med BIG DATA da du ikke skal lave lige så mange udregnigner for hver epoch. . Man kan forklare hvad Gradient Descent går ud på ved at forestille sig at man skal finde den korteste ved ned af et bjerg. Hvis man bruger traditionel Gradient Descent til at finde den korteste vej, udregner man den optimale rute på en gang ved at bruge data om alle de forskellige veje der er på bjerget. Denne løsning giver med garanti den korteste vej ned af bjerget, men det bliver også sværere og sværere at lave udregningen jo mere data man har om bjerget. Hvis man derimod bruger Stochastic Gradient Descent til at finde vej ned af bjerget, vil man gå ud og kigge på de mulige veje man kan tage på nuværende tidspunkt. Man går så ned ad den vej der fører en længst ned at bjerget. Hvis vejen er meget stejl går man lige lidt længer af denne vej inden man igen kigger efter en ny vej der fører en længere og længere ned af bjerget. Det gør man igen og igen til man har nået bunden. . Hvis vi prøver helt simpelt at overføre dette til vores neurale netværk vil det altså sige at vi tager en lille del af vores data og sender det igennem vores neurale netværk. Vi udregner gradienten for den data og bruger den til at opdatere modellens weights. Vi gør så det hele igen med en anden lille del af vores data. Denne proces kan illustreres på følgende måde: . . Init: Da vi skal have et udgangspunkt for vores weights bliver de i dette step initialiseret til tilfældige værdiger. | Predict: I dette step bruger vi de tilfældige weights til at få en prediction ved at køre en lille del af dataen igennem det neurale netværk. | Loss: I dette step bruger vi en loss function til at måle modellens effektivitet med de nuværende weights. | Gradient: I dette step udregner vi vores gradient som fortæller os hvordan ændringen af en weight vil påvirke vores loss. | Step: I dette step ændrer vi værdierne af vores weights på baggrund af den udregnede gradient. Hvis der stadig er flere epochs tilbage, går vi tilbage til step 2 og gentager de efterfølgende step. | Stop: Når der ikke er flere epochs går vi ikke tilbage til step 2 men stopper derimod bare. | Det vigtige i denne proces er altså step 4 hvor vi udregner vores gradient. Gradient er bare et fancy ord for derivative der kommer fra calculus. Så når vi siger at vi udregner vores gradient udregner vi i realiteten derivative for vores loss function. Teknisk fortalt er derivative en funktion der beregner slope for en funktion ved en given værdi. Mere simpelt fortelt fortæller derivative os hvor stejl bjerget er på en given vej. . Optimering . Smoothing (Label Smoothing) . Når vores model bliver trænet så er vores mål i teorien at få et resultat der bliver 1. Dette er resultatet på modellens “gæt” også selvom den ikke er 100% sikker. Dette betyder også at de resterende kategorier bliver 0. Denne tilgang giver tendens til overfitting, og en model som ikke giver betydelig respons på dens gæt. . For at undgå dette så kan man under opsætningen af sin model have en loss function som benytter sig af Label Smoothing. Label smoothing sørger for at modellen kommer med et mere generaliserende gæt, ved at erstatte alle 1’erne med et tal mindre end 1 og alle 0’erne med (𝝐 / N), hvor 𝝐 (epsilon) er et parameter oftest 0,1 og N er antallet af klasser. . Når vi træner modellen vil vi stadig gerne have at alle labels til sammen giver resultatet 1, derfor erstatter vi 1 (det label som der bliver gættet på) med følgende formel: (1-𝝐+𝝐/N). . This maximum is not achievable for finite zk but is approached if zy≫zk for all k≠y . Hvis man går over i den teoretiske forståelse af label smoothing, så er det en matematisk algoritme (stående ovenfor) som beviser at maximum ikke er opnåeligt. . Hvis man deler algoritmen op, så er y vores target og zy den activation som er tilhørende det target. For at komme tæt på 1, så skal zy være større end ved alle andre “gæt”. Dybere i algoritmen bliver det forklaret, at hvis modellen lærer at tildele fuld sandsynlighed på labellet ved hver træning, så er den ikke garanteret at kunne generalisere. Det som det betyder er at hvis zy har en høj/stor værdi, så skal der benyttes større weights og activations gennem modellen. Dette kan resultere i at små ændringen i input (f.eks. ændring i en pixel) kan give en helt anden probability når der bliver gættet. . Hvis man holder algoritmen op sammen med Bounded Gradient, så reducerer det modellens evne til at kunne tilpasse sig. . Sidebar . Benyttelse af Label smoothing ses ofte kun ved Single-Label. Selve matematikken bag Label smoothing er i første omgang tilegnet Single-Label, og man vil derfor skulle have en forståelse for at kunne ændre i selve algoritmens matematik for at kunne benytte Label smoothing ved Multi-Label. . Det har ikke været muligt at finde nogle endnu som har knækket den matematiske kode til at benytte Label smoothing på Multi-Label. Den offentlige debat lyder i hvert fald på at det i det nuværende omfang ikke er muligt at benytte Label smoothing på Multi-Label modeller. . Fastai . DataLoaders . DataLoaders er en meget simpel klasse, som bare wrapper/indeholder en række DataLoader objekter. Det er dog den som står for at levere data til modellen, og det er derfor en meget central del af FastAI. . Der er flere måder man kan lave ens DataLoaders objekt på. FastAI indeholder en række såkaldte “factory methods”, som returnerer DataLoaders med prædefinerede opsætninger. Det er en smart måde at spare tid på, hvis det man laver er så “almindeligt” at der allerede er en opsætning, som passer. Alternativt kan man lave en custom DataLoaders. For at gøre det, bruges data block API’en. . Når man laver en custom DataLoaders skal følgende angives, for at modellen kan trænes: . Independent variable | Dependent variable | Hvordan skal data hentes | Validation set | Labels | . Derudover kan man angive item transforms, som er noget kode der bliver kørt på hver entry i datasættet. På samme måde som med DataLoaders har FastAI en række indbyggede transforms, til de mest gængse operationer, men det er også muligt at kode sin egen. De indbyggede transforms inkluderer fx cropping og resizing af billeder. . Som et alternativ til item transforms, kan man bruge batch transforms. Med en batch transform kører man i stedet noget kode på hele batchen i stedet for hvert individuelt billede, hvilket kan være hurtigere at udføre. transform kan fx bruges i forbindelse med data augmentation af billeder, efter de er blevet croppet og/eller resizet til alle at være den samme størrelse. .",
            "url": "https://tobbe3108.github.io/BreakingGooglesRecaptcha/markdown/2021/05/25/Breaking-Google-s-Image-based-reCaptcha-v2.html",
            "relUrl": "/markdown/2021/05/25/Breaking-Google-s-Image-based-reCaptcha-v2.html",
            "date": " • May 25, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "MixUp",
            "content": "#!pip install pytorch #!pip install torchvision #!pip install fastai !pip3 install git+https://github.com/fastai/fastai.git !pip install -Uqq fastbook . rootPath = glob.glob(os.path.join(os.getcwd(), &quot;gdrive/MyDrive/**/AI_reCaptcha v2/&quot;), recursive=true)[0] path = os.path.join(rootPath, &quot;recaptcha-dataset-main/trimmed/&quot;) path . fns = get_image_files(path) fns . def get_y(r): return L(parent_label(r)) #Vi prøvede først at lave vores egen måde at loade filer ind for at begrænse datasettet # def get_image_files_by_size(path, sample_size = 200): # return list(get_image_files(path))[:sample_size] . ys = [] for i in get_image_files(path): ys.append(get_y(i)) ys . dblock = DataBlock( blocks = (ImageBlock, MultiCategoryBlock), get_items = get_image_files, get_y = get_y, splitter=RandomSplitter(valid_pct=0.2, seed=42), item_tfms=RandomResizedCrop(128, min_scale=0.35)) dls = dblock.dataloaders(path) . dls.valid.show_batch(max_n=200, nrows=10) . learn = cnn_learner(dls, resnet50, metrics=accuracy_multi, cbs=MixUp) . learn.fine_tune(20, base_lr=8.32e-03) . . lr_min,lr_steep = learn.lr_find() print(f&quot;Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}&quot;) . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) #hide_output out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn.predict(img ) #hide_output lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]}&#39; lbl_pred . learn.dls.vocab . probs . pred_idx .",
            "url": "https://tobbe3108.github.io/BreakingGooglesRecaptcha/2021/05/23/Captcha-MixUp.html",
            "relUrl": "/2021/05/23/Captcha-MixUp.html",
            "date": " • May 23, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "LabelSmoothing",
            "content": "#!pip install pytorch #!pip install torchvision #!pip install fastai !pip3 install git+https://github.com/fastai/fastai.git !pip install -Uqq fastbook . Collecting git+https://github.com/fastai/fastai.git Cloning https://github.com/fastai/fastai.git to /tmp/pip-req-build-wor6o64m Running command git clone -q https://github.com/fastai/fastai.git /tmp/pip-req-build-wor6o64m Requirement already satisfied (use --upgrade to upgrade): fastai==2.3.1 from git+https://github.com/fastai/fastai.git in /usr/local/lib/python3.7/dist-packages Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (19.3.1) Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (20.9) Requirement already satisfied: fastcore&lt;1.4,&gt;=1.3.8 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.3.19) Requirement already satisfied: torchvision&lt;0.9,&gt;=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (0.8.2) Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (3.2.2) Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.1.5) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (2.23.0) Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (3.13) Requirement already satisfied: fastprogress&gt;=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.0.0) Requirement already satisfied: pillow&gt;6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (7.1.2) Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (0.22.2.post1) Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.4.1) Requirement already satisfied: spacy&lt;3 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (2.2.4) Requirement already satisfied: torch&lt;1.8,&gt;=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.7.1) Requirement already satisfied: pyparsing&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;fastai==2.3.1) (2.4.7) Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision&lt;0.9,&gt;=0.8.2-&gt;fastai==2.3.1) (1.19.5) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai==2.3.1) (1.3.1) Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai==2.3.1) (2.8.1) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai==2.3.1) (0.10.0) Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;fastai==2.3.1) (2018.9) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (3.0.4) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (1.24.3) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (2.10) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (2020.12.5) Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;fastai==2.3.1) (1.0.1) Requirement already satisfied: srsly&lt;1.1.0,&gt;=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (1.0.5) Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (1.0.5) Requirement already satisfied: plac&lt;1.2.0,&gt;=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (1.1.3) Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (56.0.0) Requirement already satisfied: wasabi&lt;1.1.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (0.8.2) Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (2.0.5) Requirement already satisfied: catalogue&lt;1.1.0,&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (1.0.0) Requirement already satisfied: blis&lt;0.5.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (0.4.1) Requirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (4.41.1) Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (7.4.0) Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (3.0.5) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch&lt;1.8,&gt;=1.7.0-&gt;fastai==2.3.1) (3.7.4.3) Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib-&gt;fastai==2.3.1) (1.15.0) Requirement already satisfied: importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.7/dist-packages (from catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;3-&gt;fastai==2.3.1) (3.10.1) Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34;-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;3-&gt;fastai==2.3.1) (3.4.1) Building wheels for collected packages: fastai Building wheel for fastai (setup.py) ... done Created wheel for fastai: filename=fastai-2.3.1-cp37-none-any.whl size=192507 sha256=1a0978164bd115dc5983f99acfba62fa07b7f5d83395d5e23141222646a62328 Stored in directory: /tmp/pip-ephem-wheel-cache-abr5j5xb/wheels/cf/46/39/b2d08762125ed2376861976ab2c4ac30c029b86e375735d9b8 Successfully built fastai . rootPath = glob.glob(os.path.join(os.getcwd(), &quot;gdrive/MyDrive/**/AI_reCaptcha v2/&quot;), recursive=true)[0] path = os.path.join(rootPath, &quot;recaptcha-dataset-main/trimmed/&quot;) path . fns = get_image_files(path) fns . (#223) [Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (9).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (20).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (10).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (16).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (15).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (6).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (2).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (4).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (3).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (1).png&#39;)...] . def get_y(r): return L(parent_label(r)) #Vi prøvede først at lave vores egen måde at loade filer ind for at begrænse datasettet # def get_image_files_by_size(path, sample_size = 200): # return list(get_image_files(path))[:sample_size] . dblock = DataBlock( blocks = (ImageBlock(), CategoryBlock()), get_items = get_image_files, get_y = parent_label, splitter=RandomSplitter(valid_pct=0.2, seed=42), item_tfms=RandomResizedCrop(128, min_scale=0.35)) dls = dblock.dataloaders(path, bs=64) . dls.c?? . model = resnet50 learn = cnn_learner(dls, model, metrics=accuracy, cbs=MixUp, loss_func=LabelSmoothingCrossEntropy()) . lr_min,lr_steep = learn.lr_find() lr_min print(f&quot;Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}&quot;) . Minimum/10: 5.75e-07, steepest point: 1.58e-04 . learn.fine_tune(40, base_lr=5.75e-07) . epoch train_loss valid_loss accuracy time . 0 | 3.875205 | 3.655696 | 0.068182 | 00:01 | . epoch train_loss valid_loss accuracy time . 0 | 3.919041 | 3.373291 | 0.045455 | 00:01 | . 1 | 3.827166 | 3.227578 | 0.045455 | 00:01 | . 2 | 3.909230 | 3.130134 | 0.022727 | 00:01 | . 3 | 3.927115 | 3.078517 | 0.022727 | 00:01 | . 4 | 3.958529 | 3.034851 | 0.045455 | 00:01 | . 5 | 3.910722 | 2.996451 | 0.022727 | 00:01 | . 6 | 3.910551 | 3.014104 | 0.136364 | 00:01 | . 7 | 3.933049 | 3.017250 | 0.113636 | 00:01 | . 8 | 3.930960 | 3.014568 | 0.090909 | 00:01 | . 9 | 3.910522 | 3.019479 | 0.090909 | 00:01 | . 10 | 3.924200 | 3.025589 | 0.090909 | 00:01 | . 11 | 3.915815 | 3.026942 | 0.090909 | 00:01 | . 12 | 3.933930 | 3.059330 | 0.090909 | 00:01 | . 13 | 3.919611 | 3.060349 | 0.136364 | 00:01 | . 14 | 3.926650 | 3.089442 | 0.136364 | 00:01 | . 15 | 3.927249 | 3.079896 | 0.113636 | 00:01 | . 16 | 3.928542 | 3.108117 | 0.113636 | 00:01 | . 17 | 3.911227 | 3.118117 | 0.136364 | 00:01 | . 18 | 3.916621 | 3.146570 | 0.113636 | 00:01 | . 19 | 3.918973 | 3.153995 | 0.113636 | 00:01 | . 20 | 3.904037 | 3.159896 | 0.113636 | 00:01 | . 21 | 3.904909 | 3.149947 | 0.113636 | 00:01 | . 22 | 3.895804 | 3.149025 | 0.113636 | 00:01 | . 23 | 3.898803 | 3.154330 | 0.113636 | 00:01 | . 24 | 3.895025 | 3.154999 | 0.113636 | 00:01 | . 25 | 3.899476 | 3.156635 | 0.113636 | 00:01 | . 26 | 3.899348 | 3.185135 | 0.113636 | 00:01 | . 27 | 3.886115 | 3.175197 | 0.113636 | 00:01 | . 28 | 3.888682 | 3.202559 | 0.113636 | 00:01 | . 29 | 3.892341 | 3.219839 | 0.113636 | 00:01 | . 30 | 3.893173 | 3.206133 | 0.113636 | 00:01 | . 31 | 3.889893 | 3.210385 | 0.113636 | 00:01 | . 32 | 3.875875 | 3.220119 | 0.113636 | 00:01 | . 33 | 3.873398 | 3.222405 | 0.113636 | 00:01 | . 34 | 3.868398 | 3.204223 | 0.113636 | 00:01 | . 35 | 3.878595 | 3.200404 | 0.113636 | 00:01 | . 36 | 3.877649 | 3.218639 | 0.113636 | 00:01 | . 37 | 3.884450 | 3.214972 | 0.113636 | 00:01 | . 38 | 3.881060 | 3.197088 | 0.113636 | 00:01 | . 39 | 3.869617 | 3.185546 | 0.113636 | 00:01 | . . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) #hide_output out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn.predict(img ) #hide_output lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]}&#39; lbl_pred . learn.dls.vocab . probs . pred_idx .",
            "url": "https://tobbe3108.github.io/BreakingGooglesRecaptcha/2021/05/23/Captcha-LabelSmoothing.html",
            "relUrl": "/2021/05/23/Captcha-LabelSmoothing.html",
            "date": " • May 23, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "LabelSmoothing v2",
            "content": "#!pip install pytorch #!pip install torchvision #!pip install fastai !pip3 install git+https://github.com/fastai/fastai.git !pip install -Uqq fastbook . Collecting git+https://github.com/fastai/fastai.git Cloning https://github.com/fastai/fastai.git to /tmp/pip-req-build-u03iop5g Running command git clone -q https://github.com/fastai/fastai.git /tmp/pip-req-build-u03iop5g Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (19.3.1) Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (20.9) Collecting fastcore&lt;1.4,&gt;=1.3.8 Downloading https://files.pythonhosted.org/packages/d8/b0/f1fbf554e0bf3c76e1bdc3b82eedfe41fcf656479586be38c64421082b1b/fastcore-1.3.20-py3-none-any.whl (53kB) |████████████████████████████████| 61kB 5.5MB/s Requirement already satisfied: torchvision&gt;=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (0.9.1+cu101) Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (3.2.2) Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.1.5) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (2.23.0) Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (3.13) Requirement already satisfied: fastprogress&gt;=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.0.0) Requirement already satisfied: pillow&gt;6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (7.1.2) Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (0.22.2.post1) Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.4.1) Requirement already satisfied: spacy&lt;4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (2.2.4) Requirement already satisfied: torch&lt;1.9,&gt;=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.8.1+cu101) Requirement already satisfied: pyparsing&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;fastai==2.3.1) (2.4.7) Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision&gt;=0.8.2-&gt;fastai==2.3.1) (1.19.5) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai==2.3.1) (1.3.1) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai==2.3.1) (0.10.0) Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai==2.3.1) (2.8.1) Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;fastai==2.3.1) (2018.9) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (3.0.4) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (2.10) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (2020.12.5) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (1.24.3) Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;fastai==2.3.1) (1.0.1) Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (56.1.0) Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (3.0.5) Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (1.0.5) Requirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (4.41.1) Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (2.0.5) Requirement already satisfied: srsly&lt;1.1.0,&gt;=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (1.0.5) Requirement already satisfied: catalogue&lt;1.1.0,&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (1.0.0) Requirement already satisfied: wasabi&lt;1.1.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (0.8.2) Requirement already satisfied: blis&lt;0.5.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (0.4.1) Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (7.4.0) Requirement already satisfied: plac&lt;1.2.0,&gt;=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (1.1.3) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch&lt;1.9,&gt;=1.7.0-&gt;fastai==2.3.1) (3.7.4.3) Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler&gt;=0.10-&gt;matplotlib-&gt;fastai==2.3.1) (1.15.0) Requirement already satisfied: importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.7/dist-packages (from catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;4-&gt;fastai==2.3.1) (4.0.1) Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34;-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;4-&gt;fastai==2.3.1) (3.4.1) Building wheels for collected packages: fastai Building wheel for fastai (setup.py) ... done Created wheel for fastai: filename=fastai-2.3.1-cp37-none-any.whl size=193488 sha256=55ea25b7274ed51c772089493674963b6baa3f17da2b63bc81944c15630d8224 Stored in directory: /tmp/pip-ephem-wheel-cache-apdmjdk1/wheels/cf/46/39/b2d08762125ed2376861976ab2c4ac30c029b86e375735d9b8 Successfully built fastai Installing collected packages: fastcore, fastai Found existing installation: fastai 1.0.61 Uninstalling fastai-1.0.61: Successfully uninstalled fastai-1.0.61 Successfully installed fastai-2.3.1 fastcore-1.3.20 |████████████████████████████████| 727kB 9.1MB/s |████████████████████████████████| 1.2MB 48.6MB/s |████████████████████████████████| 51kB 6.6MB/s |████████████████████████████████| 51kB 8.1MB/s . cwd = os.getcwd() os.listdir(os.path.join(cwd, &quot;..&quot;)) . [&#39;tmp&#39;, &#39;sbin&#39;, &#39;var&#39;, &#39;media&#39;, &#39;root&#39;, &#39;run&#39;, &#39;srv&#39;, &#39;boot&#39;, &#39;home&#39;, &#39;mnt&#39;, &#39;proc&#39;, &#39;etc&#39;, &#39;bin&#39;, &#39;lib64&#39;, &#39;opt&#39;, &#39;sys&#39;, &#39;dev&#39;, &#39;usr&#39;, &#39;lib&#39;, &#39;content&#39;, &#39;.dockerenv&#39;, &#39;tools&#39;, &#39;datalab&#39;, &#39;tensorflow-1.15.2&#39;, &#39;lib32&#39;] . rootPath = glob.glob(os.path.join(os.getcwd(), &quot;gdrive/MyDrive/**/AI_reCaptcha v2/&quot;), recursive=true)[0] path = os.path.join(rootPath, &quot;recaptcha-dataset-main/Large/&quot;) path . &#39;/content/gdrive/MyDrive/AI_reCaptcha v2/recaptcha-dataset-main/Large/&#39; . fns = get_image_files(path) fns . (#0) [] . def get_y(r): return L(parent_label(r)) #Vi prøvede først at lave vores egen måde at loade filer ind for at begrænse datasettet # def get_image_files_by_size(path, sample_size = 200): # return list(get_image_files(path))[:sample_size] . dblock = DataBlock( blocks = (ImageBlock, MultiCategoryBlock), get_items = get_image_files, get_y = get_y, splitter=RandomSplitter(valid_pct=0.2, seed=42), item_tfms=RandomResizedCrop(128, min_scale=0.35)) dls = dblock.dataloaders(path) . dls.valid.show_batch(max_n=200, nrows=10) . learn = cnn_learner(dls, resnet50, metrics=accuracy_multi, cbs=MixUp) . lr_min,lr_steep = learn.lr_find() print(f&quot;Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}&quot;) . learn.fine_tune(200, base_lr=lr_min) . . learnerFile = path = os.path.join(rootPath, &quot;Learner_23-05.pkl&quot;) . &#39;/content/gdrive/MyDrive/AI_reCaptcha v2/Learner_04-05.pkl&#39; . learner = learn.export(fname=learnerFile) . . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) #hide_output out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn.predict(img ) #hide_output lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]}&#39; lbl_pred . learn.dls.vocab . numbers = [ f&quot;{x:.4}&quot; for x in probs ] numbers . pred_idx .",
            "url": "https://tobbe3108.github.io/BreakingGooglesRecaptcha/2021/05/23/Captcha-Label-Smoothing-v2.html",
            "relUrl": "/2021/05/23/Captcha-Label-Smoothing-v2.html",
            "date": " • May 23, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Label Correction",
            "content": "#!pip install pytorch #!pip install torchvision #!pip install fastai !pip3 install git+https://github.com/fastai/fastai.git !pip install -Uqq fastbook . Collecting git+https://github.com/fastai/fastai.git Cloning https://github.com/fastai/fastai.git to /tmp/pip-req-build-rq7prnyp Running command git clone -q https://github.com/fastai/fastai.git /tmp/pip-req-build-rq7prnyp Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (19.3.1) Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (20.9) Collecting fastcore&lt;1.4,&gt;=1.3.8 Downloading https://files.pythonhosted.org/packages/d8/b0/f1fbf554e0bf3c76e1bdc3b82eedfe41fcf656479586be38c64421082b1b/fastcore-1.3.20-py3-none-any.whl (53kB) |████████████████████████████████| 61kB 5.3MB/s Requirement already satisfied: torchvision&gt;=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (0.9.1+cu101) Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (3.2.2) Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.1.5) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (2.23.0) Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (3.13) Requirement already satisfied: fastprogress&gt;=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.0.0) Requirement already satisfied: pillow&gt;6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (7.1.2) Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (0.22.2.post1) Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.4.1) Requirement already satisfied: spacy&lt;4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (2.2.4) Requirement already satisfied: torch&lt;1.9,&gt;=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.8.1+cu101) Requirement already satisfied: pyparsing&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;fastai==2.3.1) (2.4.7) Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision&gt;=0.8.2-&gt;fastai==2.3.1) (1.19.5) Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai==2.3.1) (2.8.1) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai==2.3.1) (0.10.0) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai==2.3.1) (1.3.1) Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;fastai==2.3.1) (2018.9) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (3.0.4) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (2020.12.5) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (2.10) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (1.24.3) Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;fastai==2.3.1) (1.0.1) Requirement already satisfied: plac&lt;1.2.0,&gt;=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (1.1.3) Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (7.4.0) Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (2.0.5) Requirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (4.41.1) Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (56.0.0) Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (3.0.5) Requirement already satisfied: catalogue&lt;1.1.0,&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (1.0.0) Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (1.0.5) Requirement already satisfied: srsly&lt;1.1.0,&gt;=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (1.0.5) Requirement already satisfied: wasabi&lt;1.1.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (0.8.2) Requirement already satisfied: blis&lt;0.5.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai==2.3.1) (0.4.1) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch&lt;1.9,&gt;=1.7.0-&gt;fastai==2.3.1) (3.7.4.3) Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib-&gt;fastai==2.3.1) (1.15.0) Requirement already satisfied: importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.7/dist-packages (from catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;4-&gt;fastai==2.3.1) (3.10.1) Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34;-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;4-&gt;fastai==2.3.1) (3.4.1) Building wheels for collected packages: fastai Building wheel for fastai (setup.py) ... done Created wheel for fastai: filename=fastai-2.3.1-cp37-none-any.whl size=193493 sha256=17590a2b3cd3649d37ede345b44d956a4ec06c29e0ed55a1ab0d38251efeb624 Stored in directory: /tmp/pip-ephem-wheel-cache-p3tewc1o/wheels/cf/46/39/b2d08762125ed2376861976ab2c4ac30c029b86e375735d9b8 Successfully built fastai Installing collected packages: fastcore, fastai Found existing installation: fastai 1.0.61 Uninstalling fastai-1.0.61: Successfully uninstalled fastai-1.0.61 Successfully installed fastai-2.3.1 fastcore-1.3.20 |████████████████████████████████| 727kB 7.3MB/s |████████████████████████████████| 1.2MB 15.0MB/s |████████████████████████████████| 51kB 8.4MB/s |████████████████████████████████| 51kB 9.2MB/s . rootPath = glob.glob(os.path.join(os.getcwd(), &quot;gdrive/MyDrive/**/AI_reCaptcha v2/&quot;), recursive=true)[0] path = os.path.join(rootPath, &quot;recaptcha-dataset-main/trimmed/&quot;) path . fns = get_image_files(path) fns . def get_y(r): return L(parent_label(r)) #Vi prøvede først at lave vores egen måde at loade filer ind for at begrænse datasettet # def get_image_files_by_size(path, sample_size = 200): # return list(get_image_files(path))[:sample_size] . dblock = DataBlock( blocks = (ImageBlock, MultiCategoryBlock), get_items = get_image_files, get_y = get_y, splitter=RandomSplitter(valid_pct=0.2, seed=42), item_tfms=RandomResizedCrop(128, min_scale=0.35)) dls = dblock.dataloaders(path) . dls.valid.show_batch(max_n=200, nrows=10) . learn = cnn_learner(dls, resnet50, metrics=accuracy_multi)#, #cbs=MixUp) . lr_min,lr_steep = learn.lr_find() print(f&quot;Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}&quot;) . Minimum/10: 3.02e-02, steepest point: 3.31e-02 . learn.fine_tune(20, base_lr=2.51e-02) #learn.fine_tune(100, base_lr=lr_min) . epoch train_loss valid_loss accuracy_multi time . 0 | 0.990271 | 10.609458 | 0.252066 | 00:01 | . epoch train_loss valid_loss accuracy_multi time . 0 | 1.038216 | 2.289754 | 0.471074 | 00:01 | . 1 | 0.926491 | 1.408881 | 0.638430 | 00:01 | . 2 | 0.860209 | 1.180470 | 0.570248 | 00:01 | . 3 | 0.804445 | 1.217324 | 0.628099 | 00:01 | . 4 | 0.747300 | 1.089095 | 0.725207 | 00:01 | . 5 | 0.688723 | 1.141005 | 0.760331 | 00:01 | . 6 | 0.639391 | 0.943561 | 0.807851 | 00:01 | . 7 | 0.584238 | 0.638260 | 0.853306 | 00:01 | . 8 | 0.533574 | 0.515697 | 0.917355 | 00:01 | . 9 | 0.483738 | 0.486618 | 0.919421 | 00:01 | . 10 | 0.442470 | 0.381667 | 0.944215 | 00:01 | . 11 | 0.403672 | 0.305233 | 0.946281 | 00:01 | . 12 | 0.370747 | 0.168175 | 0.954545 | 00:01 | . 13 | 0.341409 | 0.171236 | 0.958678 | 00:01 | . 14 | 0.314833 | 0.162594 | 0.956612 | 00:01 | . 15 | 0.291693 | 0.156158 | 0.960744 | 00:01 | . 16 | 0.270791 | 0.145216 | 0.962810 | 00:01 | . 17 | 0.252393 | 0.142218 | 0.962810 | 00:01 | . 18 | 0.235803 | 0.135940 | 0.966942 | 00:01 | . 19 | 0.220654 | 0.134203 | 0.971074 | 00:01 | . . learnerFile = &#39;gdrive/MyDrive/AI_reCaptcha v2/FirstLearner.pkl&#39; . . . learner = load_learner(fname=learnerFile) . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) #hide_output out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn.predict(img ) #hide_output lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]}&#39; lbl_pred . learn.dls.vocab . [&#39;Bicycle&#39;, &#39;Bridge&#39;, &#39;Bus&#39;, &#39;Car&#39;, &#39;Chimney&#39;, &#39;Crosswalk&#39;, &#39;Hydrant&#39;, &#39;Motorcycle&#39;, &#39;Mountain&#39;, &#39;Palm&#39;, &#39;Traffic Light&#39;] . probs . tensor([4.1227e-04, 5.1589e-03, 8.6266e-04, 3.3045e-04, 1.9126e-03, 7.7007e-03, 1.0000e+00, 3.2856e-03, 8.2208e-03, 3.0211e-03, 3.0599e-03]) . pred_idx . tensor([False, False, False, False, False, False, False, False, False, False, False]) . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . interp.plot_top_losses(5, nrows=1) . target predicted probabilities loss . 0 Mountain | | tensor([0.0063, 0.0343, 0.0092, 0.0086, 0.0072, 0.0114, 0.0066, 0.0019, 0.0065, 0.0060, 0.0013]) | 0.46619924902915955 | . 1 Bridge | | tensor([0.0070, 0.0174, 0.0182, 0.0575, 0.0204, 0.0189, 0.0163, 0.0203, 0.1070, 0.1200, 0.2209]) | 0.4276248514652252 | . 2 Car | Bridge | tensor([0.0142, 0.6236, 0.0303, 0.0320, 0.0049, 0.0156, 0.0098, 0.0269, 0.0130, 0.0391, 0.0119]) | 0.4169340133666992 | . 3 Motorcycle | Bicycle | tensor([0.8674, 0.0015, 0.0017, 0.0011, 0.0278, 0.0217, 0.0013, 0.1096, 0.0029, 0.0020, 0.0274]) | 0.3927280306816101 | . 4 Crosswalk | | tensor([0.2967, 0.0108, 0.0136, 0.0066, 0.0087, 0.0322, 0.0087, 0.0271, 0.0058, 0.1519, 0.0057]) | 0.36717090010643005 | .",
            "url": "https://tobbe3108.github.io/BreakingGooglesRecaptcha/2021/05/23/Captcha-Label-Correction.html",
            "relUrl": "/2021/05/23/Captcha-Label-Correction.html",
            "date": " • May 23, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Baseline Model",
            "content": "#!pip install pytorch #!pip install torchvision #!pip install fastai !pip3 install git+https://github.com/fastai/fastai.git !pip install -Uqq fastbook . Collecting git+https://github.com/fastai/fastai.git Cloning https://github.com/fastai/fastai.git to /tmp/pip-req-build-bxxqs3wn Running command git clone -q https://github.com/fastai/fastai.git /tmp/pip-req-build-bxxqs3wn Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (19.3.1) Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (20.9) Collecting fastcore&lt;1.4,&gt;=1.3.8 Downloading https://files.pythonhosted.org/packages/0c/98/60404e2817cff113a6ae4023bc1772e23179408fdf7857fa410551758dfe/fastcore-1.3.19-py3-none-any.whl (53kB) |████████████████████████████████| 61kB 5.4MB/s Collecting torchvision&lt;0.9,&gt;=0.8 Downloading https://files.pythonhosted.org/packages/94/df/969e69a94cff1c8911acb0688117f95e1915becc1e01c73e7960a2c76ec8/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8MB) |████████████████████████████████| 12.8MB 205kB/s Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (3.2.2) Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.1.5) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (2.23.0) Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (3.13) Requirement already satisfied: fastprogress&gt;=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.0.0) Requirement already satisfied: pillow&gt;6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (7.1.2) Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (0.22.2.post1) Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (1.4.1) Requirement already satisfied: spacy&lt;3 in /usr/local/lib/python3.7/dist-packages (from fastai==2.3.1) (2.2.4) Collecting torch&lt;1.8,&gt;=1.7.0 Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB) |████████████████████████████████| 776.8MB 23kB/s Requirement already satisfied: pyparsing&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;fastai==2.3.1) (2.4.7) Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision&lt;0.9,&gt;=0.8-&gt;fastai==2.3.1) (1.19.5) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai==2.3.1) (1.3.1) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai==2.3.1) (0.10.0) Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai==2.3.1) (2.8.1) Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;fastai==2.3.1) (2018.9) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (1.24.3) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (2.10) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (3.0.4) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai==2.3.1) (2020.12.5) Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;fastai==2.3.1) (1.0.1) Requirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (4.41.1) Requirement already satisfied: catalogue&lt;1.1.0,&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (1.0.0) Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (7.4.0) Requirement already satisfied: wasabi&lt;1.1.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (0.8.2) Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (1.0.5) Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (54.2.0) Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (3.0.5) Requirement already satisfied: plac&lt;1.2.0,&gt;=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (1.1.3) Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (2.0.5) Requirement already satisfied: srsly&lt;1.1.0,&gt;=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (1.0.5) Requirement already satisfied: blis&lt;0.5.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;3-&gt;fastai==2.3.1) (0.4.1) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch&lt;1.8,&gt;=1.7.0-&gt;fastai==2.3.1) (3.7.4.3) Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler&gt;=0.10-&gt;matplotlib-&gt;fastai==2.3.1) (1.15.0) Requirement already satisfied: importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.7/dist-packages (from catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;3-&gt;fastai==2.3.1) (3.10.1) Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34;-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;3-&gt;fastai==2.3.1) (3.4.1) Building wheels for collected packages: fastai Building wheel for fastai (setup.py) ... done Created wheel for fastai: filename=fastai-2.3.1-cp37-none-any.whl size=192725 sha256=f8b39e7df8264d11e734af5d48c390f0de2c5fbc9a6df37aad66c7e9255b6c5c Stored in directory: /tmp/pip-ephem-wheel-cache-hqpkyuz4/wheels/cf/46/39/b2d08762125ed2376861976ab2c4ac30c029b86e375735d9b8 Successfully built fastai ERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you&#39;ll have torch 1.7.1 which is incompatible. Installing collected packages: fastcore, torch, torchvision, fastai Found existing installation: torch 1.8.1+cu101 Uninstalling torch-1.8.1+cu101: Successfully uninstalled torch-1.8.1+cu101 Found existing installation: torchvision 0.9.1+cu101 Uninstalling torchvision-0.9.1+cu101: Successfully uninstalled torchvision-0.9.1+cu101 Found existing installation: fastai 1.0.61 Uninstalling fastai-1.0.61: Successfully uninstalled fastai-1.0.61 Successfully installed fastai-2.3.1 fastcore-1.3.19 torch-1.7.1 torchvision-0.8.2 |████████████████████████████████| 727kB 7.3MB/s |████████████████████████████████| 1.2MB 12.3MB/s |████████████████████████████████| 51kB 8.2MB/s |████████████████████████████████| 51kB 8.6MB/s . rootPath = glob.glob(os.path.join(os.getcwd(), &quot;gdrive/MyDrive/**/AI_reCaptcha v2/&quot;), recursive=true)[0] path = os.path.join(rootPath, &quot;recaptcha-dataset-main/trimmed/&quot;) path . fns = get_image_files(path) fns . (#223) [Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (9).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (20).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (10).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (16).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (15).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (6).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (2).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (4).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (3).png&#39;),Path(&#39;gdrive/MyDrive/PBA Softwareudvikling/AI Machinelearning/AI_reCaptcha v2/recaptcha-dataset-main/trimmed/Bicycle/Bicycle (1).png&#39;)...] . def get_y(r): return L(parent_label(r)) #Vi prøvede først at lave vores egen måde at loade filer ind for at begrænse datasettet # def get_image_files_by_size(path, sample_size = 200): # return list(get_image_files(path))[:sample_size] . ys = [] for i in get_image_files(path): ys.append(get_y(i)) ys . dblock = DataBlock( blocks = (ImageBlock, MultiCategoryBlock), get_items = get_image_files, get_y = get_y, splitter=RandomSplitter(valid_pct=0.2, seed=42), item_tfms=RandomResizedCrop(128, min_scale=0.35)) dls = dblock.dataloaders(path) . dls.valid.show_batch(max_n=200, nrows=10) . learn = cnn_learner(dls, resnet50, metrics= ) . Downloading: &#34;https://download.pytorch.org/models/resnet50-19c8e357.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth . . learn.fine_tune(20, base_lr=8.32e-03) . epoch train_loss valid_loss accuracy_multi time . 0 | 0.495408 | 0.626817 | 0.776859 | 00:01 | . epoch train_loss valid_loss accuracy_multi time . 0 | 0.480477 | 0.505737 | 0.799587 | 00:01 | . 1 | 0.439666 | 0.468965 | 0.816116 | 00:01 | . 2 | 0.431645 | 0.466094 | 0.826446 | 00:01 | . 3 | 0.423222 | 0.465097 | 0.847107 | 00:01 | . 4 | 0.401796 | 0.460655 | 0.863636 | 00:01 | . 5 | 0.386039 | 0.416572 | 0.867769 | 00:01 | . 6 | 0.373970 | 0.418157 | 0.876033 | 00:01 | . 7 | 0.360508 | 0.460100 | 0.888430 | 00:01 | . 8 | 0.343545 | 0.421598 | 0.900826 | 00:01 | . 9 | 0.325515 | 0.404299 | 0.909091 | 00:01 | . 10 | 0.308734 | 0.337043 | 0.913223 | 00:01 | . 11 | 0.292258 | 0.303311 | 0.925620 | 00:01 | . 12 | 0.277903 | 0.280605 | 0.935950 | 00:01 | . 13 | 0.262055 | 0.252133 | 0.942149 | 00:01 | . 14 | 0.248708 | 0.231859 | 0.944215 | 00:01 | . 15 | 0.235359 | 0.224547 | 0.942149 | 00:01 | . 16 | 0.223245 | 0.215369 | 0.944215 | 00:01 | . 17 | 0.213816 | 0.212829 | 0.946281 | 00:01 | . 18 | 0.204845 | 0.209339 | 0.948347 | 00:01 | . 19 | 0.197136 | 0.204270 | 0.944215 | 00:01 | . . lr_min,lr_steep = learn.lr_find() print(f&quot;Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}&quot;) . Minimum/10: 8.32e-03, steepest point: 5.25e-03 . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) #hide_output out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn.predict(img ) #hide_output lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]}&#39; lbl_pred . learn.dls.vocab . [&#39;Bicycle&#39;, &#39;Bridge&#39;, &#39;Bus&#39;, &#39;Car&#39;, &#39;Chimney&#39;, &#39;Crosswalk&#39;, &#39;Hydrant&#39;, &#39;Motorcycle&#39;, &#39;Mountain&#39;, &#39;Palm&#39;, &#39;Traffic Light&#39;] . probs . tensor([0.0196, 0.9968, 0.0108, 0.0712, 0.0244, 0.0438, 0.0282, 0.0177, 0.1211, 0.2470, 0.1927]) . pred_idx . tensor([False, True, False, False, False, False, False, False, False, False, False]) . learn.export() .",
            "url": "https://tobbe3108.github.io/BreakingGooglesRecaptcha/2021/05/23/Captcha-Baseline-Model.html",
            "relUrl": "/2021/05/23/Captcha-Baseline-Model.html",
            "date": " • May 23, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://tobbe3108.github.io/BreakingGooglesRecaptcha/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://tobbe3108.github.io/BreakingGooglesRecaptcha/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://tobbe3108.github.io/BreakingGooglesRecaptcha/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}